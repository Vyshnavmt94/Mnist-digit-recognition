{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "import timeit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "import pylab as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28140 train samples\n",
      "13860 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 2\n",
    "\n",
    "df=pd.read_csv('train.csv')\n",
    "df2 = pd.get_dummies(df)\n",
    "\n",
    "x = df2.iloc[:,1:]\n",
    "y = df2.iloc[:,0]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "x_train = x_train.values.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.values.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalize to 0 to 1 range\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28140, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 11, 11, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 9, 9, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 27,818\n",
      "Trainable params: 27,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) # 26x26x8\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  #13X13X8\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))  #11X11X16\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28140 samples, validate on 13860 samples\n",
      "Epoch 1/100\n",
      "28140/28140 [==============================] - 47s 2ms/step - loss: 0.9976 - acc: 0.6557 - val_loss: 0.1734 - val_acc: 0.9494\n",
      "Epoch 2/100\n",
      "28140/28140 [==============================] - 41s 1ms/step - loss: 0.3397 - acc: 0.8981 - val_loss: 0.1138 - val_acc: 0.9665\n",
      "Epoch 3/100\n",
      "28140/28140 [==============================] - 41s 1ms/step - loss: 0.2505 - acc: 0.9291 - val_loss: 0.0973 - val_acc: 0.9714\n",
      "Epoch 4/100\n",
      "28140/28140 [==============================] - 42s 1ms/step - loss: 0.2061 - acc: 0.9382 - val_loss: 0.0911 - val_acc: 0.9738\n",
      "Epoch 5/100\n",
      "28140/28140 [==============================] - 42s 2ms/step - loss: 0.1826 - acc: 0.9459 - val_loss: 0.0776 - val_acc: 0.9768\n",
      "Epoch 6/100\n",
      "28140/28140 [==============================] - 42s 2ms/step - loss: 0.1686 - acc: 0.9495 - val_loss: 0.0701 - val_acc: 0.9796\n",
      "Epoch 7/100\n",
      "28140/28140 [==============================] - 43s 2ms/step - loss: 0.1569 - acc: 0.9531 - val_loss: 0.0684 - val_acc: 0.9811\n",
      "Epoch 8/100\n",
      "28140/28140 [==============================] - 31s 1ms/step - loss: 0.1456 - acc: 0.9558 - val_loss: 0.0670 - val_acc: 0.9820\n",
      "Epoch 9/100\n",
      "28140/28140 [==============================] - 28s 990us/step - loss: 0.1375 - acc: 0.9583 - val_loss: 0.0643 - val_acc: 0.9817\n",
      "Epoch 10/100\n",
      "28140/28140 [==============================] - 28s 980us/step - loss: 0.1359 - acc: 0.9589 - val_loss: 0.0595 - val_acc: 0.9838\n",
      "Epoch 11/100\n",
      "28140/28140 [==============================] - 28s 994us/step - loss: 0.1271 - acc: 0.9599 - val_loss: 0.0589 - val_acc: 0.9837\n",
      "Epoch 12/100\n",
      "28140/28140 [==============================] - 28s 989us/step - loss: 0.1153 - acc: 0.9635 - val_loss: 0.0563 - val_acc: 0.9843\n",
      "Epoch 13/100\n",
      "28140/28140 [==============================] - 28s 998us/step - loss: 0.1156 - acc: 0.9648 - val_loss: 0.0533 - val_acc: 0.9858\n",
      "Epoch 14/100\n",
      "28140/28140 [==============================] - 28s 993us/step - loss: 0.1092 - acc: 0.9672 - val_loss: 0.0575 - val_acc: 0.9855\n",
      "Epoch 15/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.1076 - acc: 0.9693 - val_loss: 0.0528 - val_acc: 0.9851\n",
      "Epoch 16/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.1087 - acc: 0.9663 - val_loss: 0.0546 - val_acc: 0.9870\n",
      "Epoch 17/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.1030 - acc: 0.9697 - val_loss: 0.0498 - val_acc: 0.9871\n",
      "Epoch 18/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0961 - acc: 0.9693 - val_loss: 0.0524 - val_acc: 0.9872\n",
      "Epoch 19/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0954 - acc: 0.9714 - val_loss: 0.0477 - val_acc: 0.9880\n",
      "Epoch 20/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0913 - acc: 0.9728 - val_loss: 0.0506 - val_acc: 0.9891\n",
      "Epoch 21/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0924 - acc: 0.9713 - val_loss: 0.0518 - val_acc: 0.9874\n",
      "Epoch 22/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0866 - acc: 0.9734 - val_loss: 0.0537 - val_acc: 0.9879\n",
      "Epoch 23/100\n",
      "28140/28140 [==============================] - 30s 1ms/step - loss: 0.0843 - acc: 0.9738 - val_loss: 0.0516 - val_acc: 0.9876\n",
      "Epoch 24/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0880 - acc: 0.9729 - val_loss: 0.0489 - val_acc: 0.9883\n",
      "Epoch 25/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0901 - acc: 0.9723 - val_loss: 0.0544 - val_acc: 0.9889\n",
      "Epoch 26/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0843 - acc: 0.9733 - val_loss: 0.0515 - val_acc: 0.9889\n",
      "Epoch 27/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0842 - acc: 0.9728 - val_loss: 0.0507 - val_acc: 0.9887\n",
      "Epoch 28/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0838 - acc: 0.9742 - val_loss: 0.0484 - val_acc: 0.9883\n",
      "Epoch 29/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0813 - acc: 0.9745 - val_loss: 0.0484 - val_acc: 0.9890\n",
      "Epoch 30/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0757 - acc: 0.9762 - val_loss: 0.0480 - val_acc: 0.9898\n",
      "Epoch 31/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0726 - acc: 0.9771 - val_loss: 0.0506 - val_acc: 0.9887\n",
      "Epoch 32/100\n",
      "28140/28140 [==============================] - 30s 1ms/step - loss: 0.0794 - acc: 0.9769 - val_loss: 0.0476 - val_acc: 0.9895\n",
      "Epoch 33/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0694 - acc: 0.9771 - val_loss: 0.0503 - val_acc: 0.9895\n",
      "Epoch 34/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0734 - acc: 0.9767 - val_loss: 0.0470 - val_acc: 0.9891\n",
      "Epoch 35/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0783 - acc: 0.9756 - val_loss: 0.0488 - val_acc: 0.9893\n",
      "Epoch 36/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0729 - acc: 0.9768 - val_loss: 0.0457 - val_acc: 0.9898\n",
      "Epoch 37/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0683 - acc: 0.9781 - val_loss: 0.0490 - val_acc: 0.9903\n",
      "Epoch 38/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0662 - acc: 0.9784 - val_loss: 0.0498 - val_acc: 0.9902\n",
      "Epoch 39/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0706 - acc: 0.9779 - val_loss: 0.0527 - val_acc: 0.9902\n",
      "Epoch 40/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0686 - acc: 0.9792 - val_loss: 0.0493 - val_acc: 0.9899\n",
      "Epoch 41/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0677 - acc: 0.9784 - val_loss: 0.0505 - val_acc: 0.9895\n",
      "Epoch 42/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0718 - acc: 0.9781 - val_loss: 0.0517 - val_acc: 0.9900\n",
      "Epoch 43/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0685 - acc: 0.9778 - val_loss: 0.0481 - val_acc: 0.9900\n",
      "Epoch 44/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0667 - acc: 0.9786 - val_loss: 0.0513 - val_acc: 0.9901\n",
      "Epoch 45/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0669 - acc: 0.9796 - val_loss: 0.0505 - val_acc: 0.9908\n",
      "Epoch 46/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0658 - acc: 0.9787 - val_loss: 0.0492 - val_acc: 0.9901\n",
      "Epoch 47/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0618 - acc: 0.9811 - val_loss: 0.0484 - val_acc: 0.9901\n",
      "Epoch 48/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0598 - acc: 0.9801 - val_loss: 0.0474 - val_acc: 0.9908\n",
      "Epoch 49/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0636 - acc: 0.9795 - val_loss: 0.0490 - val_acc: 0.9903\n",
      "Epoch 50/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0586 - acc: 0.9815 - val_loss: 0.0499 - val_acc: 0.9905\n",
      "Epoch 51/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0634 - acc: 0.9791 - val_loss: 0.0523 - val_acc: 0.9903\n",
      "Epoch 52/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0623 - acc: 0.9797 - val_loss: 0.0505 - val_acc: 0.9900\n",
      "Epoch 53/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0639 - acc: 0.9788 - val_loss: 0.0490 - val_acc: 0.9905\n",
      "Epoch 54/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0599 - acc: 0.9793 - val_loss: 0.0525 - val_acc: 0.9899\n",
      "Epoch 55/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0574 - acc: 0.9810 - val_loss: 0.0512 - val_acc: 0.9908\n",
      "Epoch 56/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0565 - acc: 0.9816 - val_loss: 0.0511 - val_acc: 0.9911\n",
      "Epoch 57/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0628 - acc: 0.9806 - val_loss: 0.0503 - val_acc: 0.9900\n",
      "Epoch 58/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0568 - acc: 0.9810 - val_loss: 0.0529 - val_acc: 0.9908\n",
      "Epoch 59/100\n",
      "28140/28140 [==============================] - 28s 994us/step - loss: 0.0589 - acc: 0.9809 - val_loss: 0.0511 - val_acc: 0.9910\n",
      "Epoch 60/100\n",
      "28140/28140 [==============================] - 28s 988us/step - loss: 0.0567 - acc: 0.9819 - val_loss: 0.0458 - val_acc: 0.9910\n",
      "Epoch 61/100\n",
      "28140/28140 [==============================] - 28s 994us/step - loss: 0.0570 - acc: 0.9820 - val_loss: 0.0510 - val_acc: 0.9898\n",
      "Epoch 62/100\n",
      "28140/28140 [==============================] - 28s 993us/step - loss: 0.0586 - acc: 0.9808 - val_loss: 0.0449 - val_acc: 0.9908\n",
      "Epoch 63/100\n",
      "28140/28140 [==============================] - 28s 991us/step - loss: 0.0587 - acc: 0.9799 - val_loss: 0.0496 - val_acc: 0.9908\n",
      "Epoch 64/100\n",
      "28140/28140 [==============================] - 28s 983us/step - loss: 0.0589 - acc: 0.9818 - val_loss: 0.0542 - val_acc: 0.9894\n",
      "Epoch 65/100\n",
      "28140/28140 [==============================] - 28s 987us/step - loss: 0.0549 - acc: 0.9812 - val_loss: 0.0477 - val_acc: 0.9905\n",
      "Epoch 66/100\n",
      "28140/28140 [==============================] - 28s 990us/step - loss: 0.0550 - acc: 0.9819 - val_loss: 0.0528 - val_acc: 0.9910\n",
      "Epoch 67/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0517 - acc: 0.9835 - val_loss: 0.0525 - val_acc: 0.9903\n",
      "Epoch 68/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0537 - acc: 0.9827 - val_loss: 0.0492 - val_acc: 0.9905\n",
      "Epoch 69/100\n",
      "28140/28140 [==============================] - 30s 1ms/step - loss: 0.0551 - acc: 0.9816 - val_loss: 0.0497 - val_acc: 0.9907\n",
      "Epoch 70/100\n",
      "28140/28140 [==============================] - 28s 995us/step - loss: 0.0569 - acc: 0.9827 - val_loss: 0.0595 - val_acc: 0.9891\n",
      "Epoch 71/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0524 - acc: 0.9835 - val_loss: 0.0466 - val_acc: 0.9913\n",
      "Epoch 72/100\n",
      "28140/28140 [==============================] - 28s 999us/step - loss: 0.0572 - acc: 0.9823 - val_loss: 0.0503 - val_acc: 0.9905\n",
      "Epoch 73/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0490 - acc: 0.9847 - val_loss: 0.0514 - val_acc: 0.9909\n",
      "Epoch 74/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0522 - acc: 0.9832 - val_loss: 0.0493 - val_acc: 0.9915\n",
      "Epoch 75/100\n",
      "28140/28140 [==============================] - 30s 1ms/step - loss: 0.0529 - acc: 0.9817 - val_loss: 0.0546 - val_acc: 0.9900\n",
      "Epoch 76/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0520 - acc: 0.9828 - val_loss: 0.0541 - val_acc: 0.9913\n",
      "Epoch 77/100\n",
      "28140/28140 [==============================] - 30s 1ms/step - loss: 0.0486 - acc: 0.9834 - val_loss: 0.0473 - val_acc: 0.9906\n",
      "Epoch 78/100\n",
      "28140/28140 [==============================] - 31s 1ms/step - loss: 0.0548 - acc: 0.9833 - val_loss: 0.0614 - val_acc: 0.9907\n",
      "Epoch 79/100\n",
      "28140/28140 [==============================] - 28s 996us/step - loss: 0.0532 - acc: 0.9824 - val_loss: 0.0466 - val_acc: 0.9913\n",
      "Epoch 80/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0522 - acc: 0.9838 - val_loss: 0.0540 - val_acc: 0.9905\n",
      "Epoch 81/100\n",
      "28140/28140 [==============================] - 27s 952us/step - loss: 0.0514 - acc: 0.9834 - val_loss: 0.0548 - val_acc: 0.9904\n",
      "Epoch 82/100\n",
      "28140/28140 [==============================] - 27s 945us/step - loss: 0.0571 - acc: 0.9828 - val_loss: 0.0527 - val_acc: 0.9901\n",
      "Epoch 83/100\n",
      "28140/28140 [==============================] - 27s 960us/step - loss: 0.0507 - acc: 0.9833 - val_loss: 0.0566 - val_acc: 0.9911\n",
      "Epoch 84/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0520 - acc: 0.9841 - val_loss: 0.0510 - val_acc: 0.9909\n",
      "Epoch 85/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0484 - acc: 0.9837 - val_loss: 0.0641 - val_acc: 0.9895\n",
      "Epoch 86/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0492 - acc: 0.9834 - val_loss: 0.0591 - val_acc: 0.9903\n",
      "Epoch 87/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0517 - acc: 0.9834 - val_loss: 0.0513 - val_acc: 0.9909\n",
      "Epoch 88/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0485 - acc: 0.9853 - val_loss: 0.0510 - val_acc: 0.9911\n",
      "Epoch 89/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0461 - acc: 0.9856 - val_loss: 0.0519 - val_acc: 0.9910\n",
      "Epoch 90/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0471 - acc: 0.9850 - val_loss: 0.0663 - val_acc: 0.9896\n",
      "Epoch 91/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0452 - acc: 0.9844 - val_loss: 0.0583 - val_acc: 0.9904\n",
      "Epoch 92/100\n",
      "28140/28140 [==============================] - 28s 995us/step - loss: 0.0505 - acc: 0.9846 - val_loss: 0.0534 - val_acc: 0.9916\n",
      "Epoch 93/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0500 - acc: 0.9839 - val_loss: 0.0596 - val_acc: 0.9905\n",
      "Epoch 94/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0458 - acc: 0.9845 - val_loss: 0.0551 - val_acc: 0.9906\n",
      "Epoch 95/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0450 - acc: 0.9855 - val_loss: 0.0684 - val_acc: 0.9895\n",
      "Epoch 96/100\n",
      "28140/28140 [==============================] - 30s 1ms/step - loss: 0.0538 - acc: 0.9832 - val_loss: 0.0556 - val_acc: 0.9905\n",
      "Epoch 97/100\n",
      "28140/28140 [==============================] - 28s 1ms/step - loss: 0.0476 - acc: 0.9838 - val_loss: 0.0529 - val_acc: 0.9910\n",
      "Epoch 98/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0492 - acc: 0.9851 - val_loss: 0.0579 - val_acc: 0.9894\n",
      "Epoch 99/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0511 - acc: 0.9836 - val_loss: 0.0579 - val_acc: 0.9908\n",
      "Epoch 100/100\n",
      "28140/28140 [==============================] - 29s 1ms/step - loss: 0.0523 - acc: 0.9835 - val_loss: 0.0520 - val_acc: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1680f89ba90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08174104334457225\n",
      "Test accuracy: 0.9894660894660895\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000 train samples\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('test.csv')\n",
    "df2 = pd.get_dummies(df)\n",
    "\n",
    "x = df2.iloc[:,0:]\n",
    "x = x.astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "# Normalize to 0 to 1 range\n",
    "x /= 255\n",
    "\n",
    "print(x.shape[0], 'train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[]\n",
    "for j in range(x.shape[0]):\n",
    "    z=x.iloc[j][:]\n",
    "    z = z.values.reshape(1, 28, 28, 1)\n",
    "    # input_shape = (28, 28, 1)\n",
    "    prediction = model.predict(z)\n",
    "     #print('Prediction Score:\\n',prediction[0])\n",
    "    thresholded = (prediction>0.05)*1\n",
    "     #print('\\nThresholded Score:\\n',thresholded[0])\n",
    "    digit=np.where(thresholded == 1)[1][0]\n",
    "     #print('\\nPredicted Digit:\\n',digit)\n",
    "    A.append(digit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=np.array(range(1,x.shape[0]+1))\n",
    "D=(np.vstack((id,A))).T\n",
    "imag_id=pd.DataFrame(D,columns =['ImageId','Label'])\n",
    "imag_id.set_index('ImageId')\n",
    "imag_id.to_csv(\"Digits_7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
